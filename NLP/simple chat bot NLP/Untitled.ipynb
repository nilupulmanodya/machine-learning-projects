{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding: utf-8\n",
    "# # Meet Robo: your friend\n",
    "\n",
    "import nltk\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# nltk.download() # for downloading packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import string # to process standard python strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For our example,we will be using the Wikipedia page for chatbots as our corpus.\n",
    "# Copy the contents from the page and place it in a text file named‘chatbot.txt’.\n",
    "# However, you can use any corpus of your choice.\n",
    "# We will read in the corpus.txt file\n",
    "f=open('test.txt','r',errors = 'ignore')\n",
    "raw=f.read()\n",
    "raw=raw.lower()# converts to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('punkt') # first-time use only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('wordnet') # first-time use only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# convert the entire corpus into a list of sentences and a list of words for further pre-processing\n",
    "sent_tokens = nltk.sent_tokenize(raw)# converts to list of sentences\n",
    "word_tokens = nltk.word_tokenize(raw)# converts to list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the international cricket council (icc) is the world governing body of cricket.',\n",
       " 'it was founded as the imperial cricket conference in 1909 by representatives from australia, england and south africa.']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokens[:2]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'international', 'cricket', 'council', '(']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokens[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#WordNet is a semantically-oriented dictionary of English included in NLTK.\n",
    "lemmer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "# LemTokens will take as input the tokens and return normalized tokens.\n",
    "def LemTokens(tokens):\n",
    "    return [lemmer.lemmatize(token) for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "remove_punct_dict = dict((ord(punct), None) for punct in string.punctuation)\n",
    "def LemNormalize(text):\n",
    "    return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "GREETING_INPUTS = (\"hello\", \"hi\", \"greetings\", \"sup\", \"what's up\",\"hey\",)\n",
    "GREETING_RESPONSES = [\"hi\", \"hey\", \"*nods*\", \"hi there\", \"hello\", \"I am glad! You are talking to me\"]\n",
    "\n",
    "# Checking for greetings\n",
    "# define a function for a greeting by the bot i.e if a user’s input is a greeting,\n",
    "# the bot shall return a greeting response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def greeting(sentence):\n",
    "    \"\"\"If user's input is a greeting, return a greeting response\"\"\"\n",
    "    for word in sentence.split():\n",
    "        if word.lower() in GREETING_INPUTS:\n",
    "            return random.choice(GREETING_RESPONSES)\n",
    "# the words need to be encoded as integers or floating point values\n",
    "# for use as input to a machine learning algorithm, called feature extraction (or vectorization)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# find the similarity between words entered by the user and the words in the corpus.\n",
    "# This is the simplest possible implementation of a chatbot.\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating response\n",
    "# define a function response which searches the user’s utterance for one or more known keywords\n",
    "# and returns one of several possible responses. If it doesn’t find the input matching any of the keywords,\n",
    "# it returns a response:” I am sorry! I don’t understand you”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def response(user_response):\n",
    "    robo_response=''\n",
    "    sent_tokens.append(user_response)# TF-IDF are word frequency scores that try to highlight words that are more interesting,\n",
    "    TfidfVec = TfidfVectorizer(tokenizer=LemNormalize, stop_words='english')\n",
    "    # e.g. frequent in a document but not across documents.\n",
    "    # The TfidfVectorizer will tokenize documents, learn the vocabulary and\n",
    "    # inverse document frequency weightings, and allow you to encode new documents\n",
    "    # Learn vocabulary and idf, return term-document matrix\n",
    "    # Returns X : Tf-idf-weighted sparse matrix, [n_samples, n_features] \n",
    "    tfidf = TfidfVec.fit_transform(sent_tokens)\n",
    "    # print (tfidf.shape)\n",
    "    # Cosine similarity is a measure of similarity between two non-zero vectors.\n",
    "    # Using this formula we can find out the similarity between any two documents d1 and d2.\n",
    "    # Cosine Similarity (d1, d2) = Dot product(d1, d2) / ||d1|| * ||d2||\n",
    "    vals = cosine_similarity(tfidf[-1], tfidf)\n",
    "    \n",
    "    # Cosine similarity is a measure of similarity between two non-zero vectors.\n",
    "    # Using this formula we can find out the similarity between any two documents d1 and d2.\n",
    "    # Cosine Similarity (d1, d2) = Dot product(d1, d2) / ||d1|| * ||d2||\n",
    "    vals = cosine_similarity(tfidf[-1], tfidf)\n",
    "    \n",
    "    # function is used to perform an indirect sort along the given axis using the algorithm\n",
    "    # specified by the kind keyword. It returns an array of indices of the same shape as arr\n",
    "    # that would sort the array.\n",
    "    idx=vals.argsort()[0][-2]\n",
    "    \n",
    "    # Returns a new array that is a one-dimensional flattening of this array (recursively).\n",
    "    # That is, for every element that is an array, extract its elements into the new array.\n",
    "    # If the optional level argument determines the level of recursion to flatten.\n",
    "    flat = vals.flatten()\n",
    "    \n",
    "    flat.sort()\n",
    "    req_tfidf = flat[-2]\n",
    "\n",
    "    if(req_tfidf==0):\n",
    "        robo_response=robo_response+\"I am sorry! I don't understand you\"\n",
    "        return robo_response\n",
    "    else:\n",
    "        robo_response = robo_response+sent_tokens[idx]\n",
    "        return robo_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROBO: My name is Chatty. I will answer your queries about Chatbots. If you want to exit, type Bye!\n",
      "hey\n",
      "ROBO: hi there\n",
      "hey\n",
      "ROBO: hi\n",
      "hi\n",
      "ROBO: *nods*\n",
      "heey\n",
      "ROBO: I am sorry! I don't understand you\n",
      "hey\n",
      "ROBO: *nods*\n",
      "hey\n",
      "ROBO: hey\n",
      "hi Bot\n",
      "ROBO: hey\n",
      "who is the chairman of icc\n",
      "ROBO: [9]\n",
      "\n",
      "the chairman heads the board of directors and on 26 june 2014, narayanaswami srinivasan, the former president of bcci, was announced as the first chairman of the council.\n",
      "how many members in icc\n",
      "ROBO: the icc has 105 member nations currently: 12 full members that play test matches, and 94 associate members.\n",
      "Thank you\n",
      "ROBO: You are welcome..\n"
     ]
    }
   ],
   "source": [
    "flag=True\n",
    "print(\"ROBO: My name is Chatty. I will answer your queries about Chatbots. If you want to exit, type Bye!\")\n",
    "\n",
    "while(flag==True):\n",
    "    user_response = input()\n",
    "    user_response=user_response.lower()\n",
    "    if(user_response!='bye'):\n",
    "        if(user_response=='thanks' or user_response=='thank you' ):\n",
    "            flag=False\n",
    "            print(\"ROBO: You are welcome..\")\n",
    "        else:\n",
    "            if(greeting(user_response)!=None):\n",
    "                print(\"ROBO: \"+greeting(user_response))\n",
    "            else:\n",
    "                print(\"ROBO: \",end=\"\")\n",
    "                print(response(user_response))\n",
    "                sent_tokens.remove(user_response)\n",
    "    else:\n",
    "        flag=False\n",
    "        print(\"ROBO: Bye! take care..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
